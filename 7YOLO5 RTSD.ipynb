{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51cb461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from shutil import copyfile, move\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8defceb",
   "metadata": {},
   "source": [
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –≤ YOLO-—Ñ–æ—Ä–º–∞—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d02787cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ultralytics/JSON2YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff010df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./JSON2YOLO')\n",
    "from JSON2YOLO.general_json2yolo import convert_coco_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaf68f2",
   "metadata": {},
   "source": [
    "–ù—É–∂–Ω–æ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å 274 —Å—Ç—Ä–æ–∫—É –≤ —Ñ–∞–π–ª–µ general_json2yolo.py —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
    "\n",
    "h, w, f = img['height'], img['width'], img['file_name'].split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce4698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'test_annotation'\n",
    "train_path = 'train_annotation'\n",
    "\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "move('train_anno.json', os.path.join(train_path, 'train_anno.json'))\n",
    "move('val_anno.json', os.path.join(test_path, 'val_anno.json'))\n",
    "\n",
    "for folder in ['labels', 'images']:\n",
    "    for path in [test_path, train_path]:\n",
    "        os.makedirs(os.path.join(path, folder), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf315b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations C:\\Users\\150ho\\Desktop\\DS\\–ø—Ä–æ–µ–∫—Ç\\znaki\\train_annotation\\train_anno.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54188/54188 [01:50<00:00, 490.62it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b195a07d49c74fb38ffc5367f15b1cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations C:\\Users\\150ho\\Desktop\\DS\\–ø—Ä–æ–µ–∫—Ç\\znaki\\test_annotation\\val_anno.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:09<00:00, 510.16it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a076380240124dd0ae8be19bd2abf246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "convert_coco_json(train_path)\n",
    "for file in tqdm(os.listdir(os.path.join('new_dir/labels/train_anno'))):\n",
    "    move(os.path.join('new_dir/labels/train_anno', file), os.path.join(train_path, 'labels', file))\n",
    "    \n",
    "convert_coco_json('./test_annotation/')\n",
    "for file in tqdm(os.listdir(os.path.join('new_dir/labels/val_anno'))):\n",
    "    move(os.path.join('new_dir/labels/val_anno', file), os.path.join(test_path, 'labels', file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1615be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = os.listdir(os.path.join(test_path, 'labels'))\n",
    "train_labels = os.listdir(os.path.join(train_path, 'labels'))\n",
    "\n",
    "test_labels = set(map(lambda x: x.split('.')[0], test_labels))\n",
    "train_labels = set(map(lambda x: x.split('.')[0], train_labels))\n",
    "\n",
    "images = 'rtsd-frames'\n",
    "for file in os.listdir(images):\n",
    "    name = file.split('.')[0]\n",
    "    if name in train_labels:\n",
    "        move(os.path.join(images, file), os.path.join(train_path,'images', file))\n",
    "    if name in test_labels:\n",
    "        move(os.path.join(images, file), os.path.join(test_path,'images', file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b8f7128",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_map.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a60b9f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0206276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-134-g23c4923 Python-3.9.12 torch-1.13.1+cpu CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete  (8 CPUs, 13.9 GB RAM, 211.5/237.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/ultralytics/yolov5  # clone\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install\n",
    "\n",
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c4e8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./yolov5/data/rtsd.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./yolov5/data/rtsd.yaml\n",
    "\n",
    "# train and val datasets (image directory or *.txt file with image paths)\n",
    "train: train_annotation/images  # train images (relative to 'path') \n",
    "val: test_annotation/images  # val images (relative to 'path') \n",
    "\n",
    "\n",
    "# number of classes\n",
    "nc: 155\n",
    "\n",
    "# class names\n",
    "names: ['2_1', '1_23', '1_17', '3_24', '8_2_1', '5_20', '5_19_1', '5_16', '3_25', '6_16', '7_15', '2_2', '2_4', '8_13_1', '4_2_1', '1_20_3', '1_25', '3_4', '8_3_2', '3_4_1', '4_1_6', '4_2_3', '4_1_1', '1_33', '5_15_5', '3_27', '1_15', '4_1_2_1', '6_3_1', '8_1_1', '6_7', '5_15_3', '7_3', '1_19', '6_4', '8_1_4', '8_8', '1_16', '1_11_1', '6_6', '5_15_1', '7_2', '5_15_2', '7_12', '3_18', '5_6', '5_5', '7_4', '4_1_2', '8_2_2', '7_11', '1_22', '1_27', '2_3_2', '5_15_2_2', '1_8', '3_13', '2_3', '8_3_3', '2_3_3', '7_7', '1_11', '8_13', '1_12_2', '1_20', '1_12', '3_32', '2_5', '3_1', '4_8_2', '3_20', '3_2', '2_3_6', '5_22', '5_18', '2_3_5', '7_5', '8_4_1', '3_14', '1_2', '1_20_2', '4_1_4', '7_6', '8_1_3', '8_3_1', '4_3', '4_1_5', '8_2_3', '8_2_4', '1_31', '3_10', '4_2_2', '7_1', '3_28', '4_1_3', '5_4', '5_3', '6_8_2', '3_31', '6_2', '1_21', '3_21', '1_13', '1_14', '2_3_4', '4_8_3', '6_15_2', '2_6', '3_18_2', '4_1_2_2', '1_7', '3_19', '1_18', '2_7', '8_5_4', '5_15_7', '5_14', '5_21', '1_1', '6_15_1', '8_6_4', '8_15', '4_5', '3_11', '8_18', '8_4_4', '3_30', '5_7_1', '5_7_2', '1_5', '3_29', '6_15_3', '5_12', '3_16', '1_30', '5_11', '1_6', '8_6_2', '6_8_3', '3_12', '3_33', '8_4_3', '5_8', '8_14', '8_17', '3_6', '1_26', '8_5_2', '6_8_1', '5_17', '1_10', '8_16', '7_18', '7_14', '8_23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337cf016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\150ho\\\\Desktop\\\\DS\\\\–ø—Ä–æ–µ–∫—Ç\\\\znaki\\\\yolov5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8f0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./yolov5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "778d0596",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 1280 --batch -1 --epochs 10 --data rtsd.yaml --weights yolov5m6.pt --project \"RTSD\" --name \"yolov5m6\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "0728e6bd",
   "metadata": {},
   "source": [
    "2023-04-06 08:24:17.763980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2023-04-06 08:24:18.773994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
    "train: weights=yolov5m6.pt, cfg=, data=rtsd.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=-1, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=RTSD, name=yolov5m6, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
    "github: up to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
    "YOLOv5 üöÄ v7.0-134-g23c4923 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
    "\n",
    "hyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
    "ClearML: run 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
    "Comet: run 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
    "TensorBoard: Start with 'tensorboard --logdir RTSD', view at http://localhost:6006/\n",
    "Overriding model.yaml nc=80 with nc=155\n",
    "\n",
    "                 from  n    params  module                                  arguments                     \n",
    "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
    "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
    "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
    "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
    "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
    "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
    "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
    "  7                -1  1   1991808  models.common.Conv                      [384, 576, 3, 2]              \n",
    "  8                -1  2   2327040  models.common.C3                        [576, 576, 2]                 \n",
    "  9                -1  1   3982848  models.common.Conv                      [576, 768, 3, 2]              \n",
    " 10                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
    " 11                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
    " 12                -1  1    443520  models.common.Conv                      [768, 576, 1, 1]              \n",
    " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
    " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
    " 15                -1  2   2658816  models.common.C3                        [1152, 576, 2, False]         \n",
    " 16                -1  1    221952  models.common.Conv                      [576, 384, 1, 1]              \n",
    " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
    " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
    " 19                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
    " 20                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
    " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
    " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
    " 23                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
    " 24                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
    " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
    " 26                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
    " 27                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
    " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
    " 29                -1  2   2437632  models.common.C3                        [768, 576, 2, False]          \n",
    " 30                -1  1   2987136  models.common.Conv                      [576, 576, 3, 2]              \n",
    " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
    " 32                -1  2   4429824  models.common.C3                        [1152, 768, 2, False]         \n",
    " 33  [23, 26, 29, 32]  1    923520  models.yolo.Detect                      [155, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [192, 384, 576, 768]]\n",
    "Model summary: 379 layers, 36164832 parameters, 36164832 gradients, 51.3 GFLOPs\n",
    "\n",
    "Transferred 619/627 items from yolov5m6.pt\n",
    "AMP: checks passed ‚úÖ\n",
    "AutoBatch: Computing optimal batch size for --imgsz 1280\n",
    "AutoBatch: CUDA:0 (Tesla T4) 14.75G total, 0.61G reserved, 0.28G allocated, 13.86G free\n",
    "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
    "    36164832         205         1.768         49.76         76.53      (1, 3, 1280, 1280)                    list\n",
    "    36164832         410         3.320         61.03         89.31      (2, 3, 1280, 1280)                    list\n",
    "    36164832         820         6.082         122.9           152      (4, 3, 1280, 1280)                    list\n",
    "    36164832        1640        11.740         251.4         280.3      (8, 3, 1280, 1280)                    list\n",
    "CUDA out of memory. Tried to allocate 76.00 MiB (GPU 0; 14.75 GiB total capacity; 14.35 GiB already allocated; 28.81 MiB free; 14.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
    "AutoBatch: Using batch-size 7 for CUDA:0 11.22G/14.75G (76%) ‚úÖ\n",
    "optimizer: SGD(lr=0.01) with parameter groups 103 weight(decay=0.0), 107 weight(decay=0.0004921875), 107 bias\n",
    "albumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
    "train: Scanning /content/yolov5/train_annotation/labels.cache... 54188 images, 0 backgrounds, 0 corrupt: 100% 54188/54188 [00:00<?, ?it/s]\n",
    "val: Scanning /content/yolov5/test_annotation/labels.cache... 5000 images, 0 backgrounds, 0 corrupt: 100% 5000/5000 [00:00<?, ?it/s]\n",
    "\n",
    "AutoAnchor: 3.85 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
    "Plotting labels to RTSD/yolov5m65/labels.jpg... \n",
    "Image sizes 1280 train, 1280 val\n",
    "Using 2 dataloader workers\n",
    "Logging results to RTSD/yolov5m65\n",
    "Starting training for 10 epochs...\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "        0/9      10.9G    0.02729    0.01036    0.05008          3       1280: 100% 7742/7742 [1:49:42<00:00,  1.18it/s]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 358/358 [02:58<00:00,  2.00it/s]\n",
    "                   all       5000       8866      0.958     0.0693     0.0854     0.0577\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "        1/9      11.4G    0.02356      0.006    0.02908          1       1280: 100% 7742/7742 [1:47:44<00:00,  1.20it/s]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 358/358 [02:57<00:00,  2.02it/s]\n",
    "                   all       5000       8866      0.908      0.174        0.2       0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d50d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17332362",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112778de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36df258",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/yolov5/RTSD/yolov5m65 /content/drive/MyDrive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
