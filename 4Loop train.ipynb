{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e709c4a",
   "metadata": {},
   "source": [
    "# Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ad15dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import random\n",
    "import cv2\n",
    "from pycocotools.coco import COCO\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "\n",
    "from torchvision.models import mobilenet_v3_large, resnet152\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b29382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1210a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp /content/drive/MyDrive/chkpt_model1a_d_0.pth ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a95e0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp chkpt_model1a_d_0.pth /content/drive/MyDrive\n",
    "# !cp chkpt_m1a_d_0.pth /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e7d5782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_id = -1\n",
    "device = 'cpu' if device_id == -1 else f'cuda:{device_id}'\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 6\n",
    "classes = 2\n",
    "classes1 = 156\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144a1dc",
   "metadata": {},
   "source": [
    "### models DETECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed98ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1_train = []\n",
    "loss1_val = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start = time.time()\n",
    "    model1.train()\n",
    "    for i, batch in enumerate(data_loader_train1):\n",
    "        optimizer1.zero_grad()\n",
    "        loss_train = 0\n",
    "        imgs, targets = batch\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model1(imgs, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_train += losses.item()\n",
    "        losses.backward()\n",
    "        optimizer1.step()\n",
    "        \n",
    "        if i % 200 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {losses.item()}')\n",
    "    \n",
    "    loss11_train = (loss_train / i)\n",
    "    loss1_train.append(loss11_train)\n",
    "    \n",
    "    print('Эпоха train:', epoch,'Итераций:', i, 'train loss:', (loss_train / i))\n",
    "    \n",
    "    for i, batch in enumerate(data_loader_val1):\n",
    "        optimizer1.zero_grad()\n",
    "        loss_val = 0\n",
    "        imgs, targets = batch\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        with torch.no_grad():\n",
    "              loss_dict = model1(imgs, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_val += losses.item()\n",
    "        \n",
    "        if i % 200 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {losses.item()}')\n",
    "    \n",
    "    loss11_val = (loss_val / i)\n",
    "    loss1_val.append(loss11_val)\n",
    "    \n",
    "#     lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer1, step_size=, gamma=0.5)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n",
    "    print('Эпоха val:', epoch, 'Итераций:', i, 'val loss:', (loss_val / i))\n",
    "    \n",
    "        \n",
    "    torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': model1.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer1.state_dict(),\n",
    "                    'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "                    'loss_train': loss1_train,\n",
    "                    'loss_val': loss1_val,\n",
    "                    }, f'./chkpt_model1_d_{epoch}.pth')\n",
    "    \n",
    "    torch.save(model1.state_dict(), f'./chkpt_m1_d_{epoch}.pth')\n",
    "    !cp chkpt_model1_d_{epoch}.pth /content/drive/MyDrive\n",
    "    !cp chkpt_m1_d_{epoch}.pth /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d81e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df997380",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots()\n",
    "ax.plot(loss1_train, label='Train')\n",
    "ax.plot(loss1_val, label='Val')\n",
    "ax.set(xlabel='Epoch', ylabel='Loss')\n",
    "ax.savefig(f\"./loss_d.png\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4051dcc8",
   "metadata": {},
   "source": [
    "### models CLASSIFIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb211b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, valid_loss = [], []\n",
    "train_acc, valid_acc = [], []   \n",
    "\n",
    "y_true_t, y_true_v = [], []\n",
    "y_pred_t, y_pred_v = [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    train_class_correct = list(0. for i in range(classes1))\n",
    "    train_class_total = list(0. for i in range(classes1))\n",
    "    for i, batch in enumerate(data_loader_train22):\n",
    "        optimizer.zero_grad()\n",
    "        image, targets = batch['images'].to(device), batch['targets'].to(device)\n",
    "#         image = list(img.to(device) for img in image)\n",
    "#         targets = [t.to(device) for t in targets]\n",
    "        # Forward pass.\n",
    "        outputs = model(image)\n",
    "        # Calculate the loss.\n",
    "        loss = loss_func(outputs, targets)\n",
    "        train_running_loss += loss.item()\n",
    "        # Calculate the accuracy.\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_running_correct += (preds == targets).sum().item()\n",
    "        correct  = (preds == targets).squeeze()\n",
    "        for a in range(len(preds)):\n",
    "                label = targets[a]\n",
    "                # print(label)\n",
    "                train_class_correct[label] += correct[a].item()\n",
    "                train_class_total[label] += 1\n",
    "        # Backpropagation.\n",
    "        loss.backward()\n",
    "        # Update the weights.\n",
    "        optimizer.step()     \n",
    "        \n",
    "        y_true_t.extend([int(item) for item in targets])\n",
    "        y_pred_t.extend([int(item) for item in preds])\n",
    "        \n",
    "        if i % 400 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "    \n",
    "    # Loss and accuracy for the complete epoch.\n",
    "    train_epoch_loss = train_running_loss / i\n",
    "    train_epoch_acc = 100. * (train_running_correct / len(df222))\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_epoch_accuracy = metrics.accuracy_score(y_true_t, y_pred_t)\n",
    "    train_epoch_f1_micro = metrics.f1_score(y_true_t, y_pred_t, average=\"micro\")\n",
    "    train_epoch_f1_macro =  metrics.f1_score(y_true_t, y_pred_t, average=\"macro\")\n",
    "    train_epoch_f1_weighted = metrics.f1_score(y_true_t, y_pred_t, average=\"weighted\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Эпоха train:', epoch,'Итераций:', i, 'train loss:', train_epoch_loss, 'train acc:', train_epoch_acc)\n",
    "    \n",
    "    model.eval()\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    # We need two lists to keep track of class-wise accuracy.\n",
    "    class_correct = list(0. for i in range(classes1))\n",
    "    class_total = list(0. for i in range(classes1))\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader_val22):\n",
    "#             image, targets = batch\n",
    "            image, targets = batch['images'].to(device), batch['targets'].to(device)\n",
    "#             image = list(img.to(device) for img in image)\n",
    "#             targets = [t.to(device) for t in targets]\n",
    "            # Forward pass.\n",
    "            outputs = model(image)\n",
    "            # Calculate the loss.\n",
    "            loss = loss_func(outputs, targets)\n",
    "            valid_running_loss += loss.item()\n",
    "            # Calculate the accuracy.\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            valid_running_correct += (preds == targets).sum().item()\n",
    "            # Calculate the accuracy for each class.\n",
    "            correct  = (preds == targets).squeeze()\n",
    "            for j in range(len(preds)):\n",
    "                label = targets[j]\n",
    "                # print(label)\n",
    "                class_correct[label] += correct[j].item()\n",
    "                class_total[label] += 1\n",
    "        \n",
    "            if i % 400 == 0:\n",
    "                 print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
    "                    \n",
    "            y_true_v.extend([int(item) for item in targets])\n",
    "            y_pred_v.extend([int(item) for item in preds])\n",
    "        \n",
    "    # Loss and accuracy for the complete epoch.\n",
    "    valid_epoch_loss = valid_running_loss / i\n",
    "    valid_epoch_acc = 100. * (valid_running_correct / len(df122))\n",
    "    \n",
    "    valid_epoch_accuracy = metrics.accuracy_score(y_true_v, y_pred_v)\n",
    "    valid_epoch_f1_micro = metrics.f1_score(y_true_v, y_pred_v, average=\"micro\")\n",
    "    valid_epoch_f1_macro =  metrics.f1_score(y_true_v, y_pred_v, average=\"macro\")\n",
    "    valid_epoch_f1_weighted = metrics.f1_score(y_true_v, y_pred_v, average=\"weighted\")\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n",
    "    print('Эпоха val:', epoch, 'Итераций:', i, 'val loss:', valid_epoch_loss, 'val acc:', valid_epoch_acc)\n",
    "    \n",
    "    train_loss.append(train_epoch_loss)\n",
    "    valid_loss.append(valid_epoch_loss)\n",
    "    train_acc.append(train_epoch_acc)\n",
    "    valid_acc.append(valid_epoch_acc)\n",
    "    \n",
    "    torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'accuracy_train': train_epoch_accuracy,\n",
    "                    'f1_micro_trainl': train_epoch_f1_micro,\n",
    "                    'f1_macro_train': train_epoch_f1_macro,\n",
    "                    'f1_weighted_train': train_epoch_f1_weighted,\n",
    "                    'loss_train': train_loss,\n",
    "                    'acc_train': train_acc,\n",
    "                    'accuracy_val': valid_epoch_accuracy,\n",
    "                    'f1_micro_val': valid_epoch_f1_micro,\n",
    "                    'f1_macro_val': valid_epoch_f1_macro,\n",
    "                    'f1_weighted_val': valid_epoch_f1_weighted,\n",
    "                    'loss_val': valid_loss,\n",
    "                    'acc_val': valid_acc\n",
    "                    }, f'./chkpt_model_clf_{epoch}.pth')\n",
    "    \n",
    "    torch.save(model.state_dict(), f'./chkpt_m_clf_{epoch}.pth')\n",
    "    !cp chkpt_model_clf_{epoch}.pth /content/drive/MyDrive\n",
    "    !cp chkpt_m_clf_{epoch}.pth /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fabc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9352ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots()\n",
    "ax.plot(train_loss, label='Train')\n",
    "ax.plot(valid_loss, label='Val')\n",
    "ax.set(xlabel='Epoch', ylabel='Loss')\n",
    "ax.savefig(f\"./loss_clf.png\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots()\n",
    "ax.plot(train_acc, label='Train')\n",
    "ax.plot(valid_lacc, label='Val')\n",
    "ax.set(xlabel='Epoch', ylabel='Loss')\n",
    "ax.savefig(f\"./loss1.png\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
